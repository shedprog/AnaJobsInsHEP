{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os, time, json, argparse, datetime as dt\nfrom typing import Dict, Optional, Set, Tuple, List\nimport requests","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"execution_failed":"2025-09-13T20:36:54.380Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"YEARS_BACK = 20\nEND_YEAR   = dt.date.today().year\nOUT_DIR    = \"/kaggle/working/inspire_jobs\"\n\nBASE_URL   = \"https://inspirehep.net/api/jobs\"\nPAGE_SIZE  = 1000     # API max per page\nSLEEP_S    = 0.35     # be polite; helps with rate limits\nTIMEOUT_S  = 60\nRETRY_BACKOFF = [2, 4, 8]  # seconds for transient errors\n\n# Avoid email-bearing fields for ToU compliance (e.g., contact_details, reference_letters).\nFIELDS = [\n    \"position\",\"ranks\",\"regions\",\"status\",\"deadline_date\",\n    \"arxiv_categories\",\"accelerator_experiments\",\"institutions\",\n    \"description\",\"urls\",\"public_notes\",\n    \"external_job_identifier\",\"external_system_identifiers\",\n    \"control_number\",\"legacy_creation_date\",\"legacy_version\",\"deleted\",\"deleted_records\",\n]\n\nHEADERS = {\"User-Agent\": \"kaggle-inspire-jobs-downloader/1.0 (+https://www.kaggle.com/)\"}","metadata":{"execution":{"execution_failed":"2025-09-13T20:36:54.380Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ---------------- Helper functions --------------\ndef month_ranges(year: int) -> List[Tuple[str, str]]:\n    out = []\n    for m in range(1, 13):\n        start = dt.date(year, m, 1)\n        end = (dt.date(year + (m==12), 1 if m==12 else m+1, 1) - dt.timedelta(days=1))\n        out.append((start.isoformat(), end.isoformat()))\n    return out\n\ndef build_params(q_str: str, first_page: bool = True) -> Dict[str, str]:\n    if not first_page:\n        return {}\n    return {\n        \"q\": q_str,\n        \"size\": str(PAGE_SIZE),\n        \"fields\": \",\".join(FIELDS),\n        \"sort\": \"mostrecent\",  # jobs also supports 'deadline'\n    }\n\ndef get_json(url: str, params: Optional[Dict[str, str]] = None) -> Dict:\n    for attempt, backoff in enumerate([0] + RETRY_BACKOFF):\n        if backoff:\n            time.sleep(backoff)\n        resp = requests.get(url, headers=HEADERS, params=params, timeout=TIMEOUT_S)\n        if resp.status_code == 429:\n            time.sleep(6)  # wait out the window\n            continue\n        if 500 <= resp.status_code < 600:\n            continue\n        resp.raise_for_status()\n        return resp.json()\n    resp.raise_for_status()\n    return {}\n\ndef count_only(query: str) -> int:\n    # Peek first page to read total\n    data = get_json(BASE_URL, build_params(query, first_page=True) | {\"page\": \"1\"})\n    total = data.get(\"hits\", {}).get(\"total\", 0)\n    return total if isinstance(total, int) else total.get(\"value\", 0)\n\ndef page_through(query: str, writer, ids_seen: Set[str]) -> int:\n    url = BASE_URL\n    params = build_params(query, first_page=True)\n    wrote = 0\n    while url:\n        data = get_json(url, params)\n        params = None  # subsequent: follow absolute links.next\n        hits = data.get(\"hits\", {}).get(\"hits\", [])\n        for hit in hits:\n            rec_id = hit.get(\"id\") or hit.get(\"metadata\", {}).get(\"control_number\")\n            if rec_id and rec_id in ids_seen:\n                continue\n            if rec_id:\n                ids_seen.add(rec_id)\n            writer.write(json.dumps(hit, ensure_ascii=False) + \"\\n\")\n            wrote += 1\n        url = data.get(\"links\", {}).get(\"next\")\n        if url:\n            time.sleep(SLEEP_S)\n    return wrote\n\ndef download_year(year: int, out_dir: str) -> int:\n    os.makedirs(out_dir, exist_ok=True)\n    out_path = os.path.join(out_dir, f\"jobs_{year}.jsonl\")\n\n    y0, y1 = f\"{year}-01-01\", f\"{year}-12-31\"\n    year_q = f\"deadline_date:[{y0} TO {y1}]\"\n\n    print(f\"\\n=== {year} ===\")\n    total_est = count_only(year_q)\n    print(f\"Estimated results: {total_est}\")\n\n    ids_seen: Set[str] = set()\n    wrote_total = 0\n    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n        if total_est <= 9500:  # well under the ~10k/search ceiling\n            wrote_total = page_through(year_q, f, ids_seen)\n        else:\n            print(\"Large year; splitting by month to avoid per-query cap…\")\n            for (start, end) in month_ranges(year):\n                sub_q = f\"deadline_date:[{start} TO {end}]\"\n                sub_est = count_only(sub_q)\n                print(f\"  {start}..{end}: ~{sub_est}\")\n                wrote_total += page_through(sub_q, f, ids_seen)\n\n    print(f\"Wrote {wrote_total} records → {out_path}\")\n    return wrote_total","metadata":{"trusted":true,"execution":{"execution_failed":"2025-09-13T20:36:54.380Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"start_year = END_YEAR - (YEARS_BACK - 1)\nprint(f\"Downloading INSPIRE HEP job ads {start_year}..{END_YEAR} → {OUT_DIR}\")\ntotals = {}\nfor y in range(start_year, END_YEAR + 1):\n    totals[y] = download_year(y, OUT_DIR)\n\nprint(\"\\nSummary (records per file):\")\nfor y in range(start_year, END_YEAR + 1):\n    print(f\"  {y}: {totals.get(y, 0)}\")\n\nprint(\"\\nFiles written:\")\nfor fn in sorted(os.listdir(OUT_DIR)):\n    if fn.endswith(\".jsonl\"):\n        print(\" \", os.path.join(OUT_DIR, fn))","metadata":{"trusted":true,"execution":{"execution_failed":"2025-09-13T20:36:54.380Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}